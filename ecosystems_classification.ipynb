{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c6225d",
   "metadata": {},
   "source": [
    "## Environment Identifier\n",
    "This model will be trained on google maps images of overview images of various ecosystems and use supervised categorical machine learning to identify various types of terestrial ecosystems:\n",
    "#### forest\n",
    "#### desert\n",
    "#### grassland\n",
    "#### tundra\n",
    "I am not sure if I want to add urban to the list of ecosystems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3836583d",
   "metadata": {},
   "source": [
    "### Import all the stuff for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "747bcc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                                \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # silence all the tensorflow warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecf3728",
   "metadata": {},
   "source": [
    "### import images from the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af7784b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "base_dir = \"./ecosystems/\"\n",
    "forest_dir = os.path.join(base_dir, 'forest/')\n",
    "grassland_dir = os.path.join(base_dir, 'grassland/')\n",
    "tundra_dir = os.path.join(base_dir, 'tundra/')\n",
    "desert_dir = os.path.join(base_dir, 'desert/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d039f1",
   "metadata": {},
   "source": [
    "### train on just forest and desert, use k-means clustering.\n",
    "I am getting impatiant, I just want to see if it can even get forest vs. desert with about 500 pics of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d1695a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1408 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = image_dataset_from_directory(base_dir, labels='inferred',image_size = (250,250),batch_size=64)\n",
    "iterator = iter(dataset)\n",
    "batch_size = 64\n",
    "num_batches = 22\n",
    "x_train = []\n",
    "y_train = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5ab0fabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
      "137\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset))\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "c7f08a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(250, 250, 3)))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "f03ef095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- on epoch number: 1\n",
      "batch #0\n",
      "1/1 [==============================] - 1s 727ms/step - loss: 33.6281\n",
      "batch #1\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 13257.2773\n",
      "batch #2\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 14664.1055\n",
      "batch #3\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 5788.6445\n",
      "batch #4\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 1279.0181\n",
      "batch #5\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 3991.9275\n",
      "batch #6\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 669.8765\n",
      "batch #7\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 1597.7090\n",
      "batch #8\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 1240.9758\n",
      "batch #9\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 420.0269\n",
      "batch #10\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0000e+00\n",
      "batch #11\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 273.0587\n",
      "batch #12\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 92.1031\n",
      "batch #13\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0000e+00\n",
      "batch #14\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 1285.6952\n",
      "batch #15\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0000e+00\n",
      "batch #16\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0000e+00\n",
      "batch #17\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 576.2527\n",
      "batch #18\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 175.8113\n",
      "batch #19\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0000e+00\n",
      "batch #20\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 760.0109\n",
      "batch #21\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.0000e+00\n",
      "batch #22\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #23\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #24\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 228.9794\n",
      "batch #25\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0000e+00\n",
      "batch #26\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0000e+00\n",
      "batch #27\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 211.4283\n",
      "batch #28\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0000e+00\n",
      "batch #29\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.0000e+00\n",
      "batch #30\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0000e+00\n",
      "batch #31\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0000e+00\n",
      "batch #32\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.0000e+00\n",
      "batch #33\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 35.2652\n",
      "batch #34\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0000e+00\n",
      "batch #35\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0000e+00\n",
      "batch #36\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 1153.8040\n",
      "batch #37\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 222.5137\n",
      "batch #38\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 978.3027\n",
      "batch #39\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 124.6277\n",
      "batch #40\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0000e+00\n",
      "batch #41\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 6752.0498\n",
      "batch #42\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0000e+00\n",
      "batch #43\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.0000e+00\n",
      "batch #44\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 724.0052\n",
      "batch #45\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 69.2428\n",
      "batch #46\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 595.0044\n",
      "batch #47\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0000e+00\n",
      "batch #48\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 2744.3911\n",
      "batch #49\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 341.4920\n",
      "batch #50\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 67.4443\n",
      "batch #51\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.0000e+00\n",
      "batch #52\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0000e+00\n",
      "batch #53\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 374.0471\n",
      "batch #54\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.0000e+00\n",
      "batch #55\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 207.6525\n",
      "batch #56\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 47.5208\n",
      "batch #57\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.0000e+00\n",
      "batch #58\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 67.5631\n",
      "batch #59\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0000e+00\n",
      "batch #60\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 632.3999\n",
      "batch #61\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 267.7242\n",
      "batch #62\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #63\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0000e+00\n",
      "batch #64\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0000e+00\n",
      "batch #65\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #66\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0000e+00\n",
      "batch #67\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 78.7879\n",
      "batch #68\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.0000e+00\n",
      "batch #69\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0000e+00\n",
      "batch #70\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.0000e+00\n",
      "batch #71\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 23.1906\n",
      "batch #72\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 616.3225\n",
      "batch #73\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 163.0614\n",
      "batch #74\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0000e+00\n",
      "batch #75\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 60.1198\n",
      "batch #76\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0000e+00\n",
      "batch #77\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 969.1573\n",
      "batch #78\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0000e+00\n",
      "batch #79\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0000e+00\n",
      "batch #80\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 1276.3334\n",
      "batch #81\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 3200.6768\n",
      "batch #82\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0000e+00\n",
      "batch #83\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 436.7772\n",
      "batch #84\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.0000e+00\n",
      "batch #85\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 4231.7734\n",
      "batch #86\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0000e+00\n",
      "batch #87\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.0000e+00\n",
      "batch #88\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.0000e+00\n",
      "batch #89\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0000e+00\n",
      "batch #90\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 721.9862\n",
      "batch #91\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 651.7254\n",
      "batch #92\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0000e+00\n",
      "batch #93\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0000e+00\n",
      "batch #94\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 58.3267\n",
      "batch #95\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0000e+00\n",
      "batch #96\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 1523.4762\n",
      "batch #97\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.0000e+00\n",
      "batch #98\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0000e+00\n",
      "batch #99\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 2710.1929\n",
      "batch #100\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0000e+00\n",
      "batch #101\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #102\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0000e+00\n",
      "batch #103\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0000e+00\n",
      "batch #104\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.0000e+00\n",
      "batch #105\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.0000e+00\n",
      "batch #106\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 1428.9778\n",
      "batch #107\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 1582.2739\n",
      "batch #108\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 70.4435\n",
      "batch #109\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0000e+00\n",
      "batch #110\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.0000e+00\n",
      "batch #111\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0000e+00\n",
      "batch #112\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0000e+00\n",
      "batch #113\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0000e+00\n",
      "batch #114\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 62.4393\n",
      "batch #115\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.0000e+00\n",
      "batch #116\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 517.5236\n",
      "batch #117\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.0000e+00\n",
      "batch #118\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0000e+00\n",
      "batch #119\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 122.4456\n",
      "batch #120\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 1043.7544\n",
      "batch #121\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0000e+00\n",
      "batch #122\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.0000e+00\n",
      "batch #123\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 457.9902\n",
      "batch #124\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0000e+00\n",
      "batch #125\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0000e+00\n",
      "batch #126\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0000e+00\n",
      "batch #127\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 6.7884e-14\n",
      "batch #128\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0000e+00\n",
      "batch #129\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0000e+00\n",
      "batch #130\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 14.6472\n",
      "batch #131\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0000e+00\n",
      "batch #132\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 764.1833\n",
      "batch #133\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0000e+00\n",
      "batch #134\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0000e+00\n",
      "batch #135\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0000e+00\n",
      "batch #136\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0000e+00\n",
      "---------------- on epoch number: 2\n",
      "batch #0\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.0000e+00\n",
      "batch #1\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0000e+00\n",
      "batch #2\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.0000e+00\n",
      "batch #3\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0000e+00\n",
      "batch #4\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0000e+00\n",
      "batch #5\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0000e+00\n",
      "batch #6\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0000e+00\n",
      "batch #7\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0000e+00\n",
      "batch #8\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0000e+00\n",
      "batch #9\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0000e+00\n",
      "batch #10\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0000e+00\n",
      "batch #11\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0000e+00\n",
      "batch #12\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0000e+00\n",
      "batch #13\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0000e+00\n",
      "batch #14\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0000e+00\n",
      "batch #15\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0000e+00\n",
      "batch #16\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0000e+00\n",
      "batch #17\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0000e+00\n",
      "batch #18\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0000e+00\n",
      "batch #19\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0000e+00\n",
      "batch #20\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0000e+00\n",
      "batch #21\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0000e+00\n",
      "batch #22\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #23\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0000e+00\n",
      "batch #24\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0000e+00\n",
      "batch #25\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #26\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 370.3922\n",
      "batch #27\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0000e+00\n",
      "batch #28\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0000e+00\n",
      "batch #29\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0000e+00\n",
      "batch #30\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0000e+00\n",
      "batch #31\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0000e+00\n",
      "batch #32\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0000e+00\n",
      "batch #33\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0000e+00\n",
      "batch #34\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0000e+00\n",
      "batch #35\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 1399.5743\n",
      "batch #36\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0000e+00\n",
      "batch #37\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0000e+00\n",
      "batch #38\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0000e+00\n",
      "batch #39\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #40\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0000e+00\n",
      "batch #41\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 2712.9858\n",
      "batch #42\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0000e+00\n",
      "batch #43\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0000e+00\n",
      "batch #44\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 1720.9674\n",
      "batch #45\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 3655.0801\n",
      "batch #46\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 1360.9048\n",
      "batch #47\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 1682.5623\n",
      "batch #48\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #49\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 340.6200\n",
      "batch #50\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 751.0898\n",
      "batch #51\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #52\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 639.5074\n",
      "batch #53\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0000e+00\n",
      "batch #54\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0000e+00\n",
      "batch #55\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #56\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0000e+00\n",
      "batch #57\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0000e+00\n",
      "batch #58\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0000e+00\n",
      "batch #59\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 552.8945\n",
      "batch #60\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 366.4296\n",
      "batch #61\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0000e+00\n",
      "batch #63\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0000e+00\n",
      "batch #64\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0000e+00\n",
      "batch #65\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 20.5622\n",
      "batch #66\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 332.9701\n",
      "batch #67\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0000e+00\n",
      "batch #68\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 533.0807\n",
      "batch #69\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 240.9626\n",
      "batch #70\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #71\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 610.2748\n",
      "batch #72\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #73\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0000e+00\n",
      "batch #74\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 452.1481\n",
      "batch #75\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0000e+00\n",
      "batch #76\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0000e+00\n",
      "batch #77\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0000e+00\n",
      "batch #78\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 47.4835\n",
      "batch #79\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #80\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0000e+00\n",
      "batch #81\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0000e+00\n",
      "batch #82\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0000e+00\n",
      "batch #83\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0000e+00\n",
      "batch #84\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0000e+00\n",
      "batch #85\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 170.5395\n",
      "batch #86\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #87\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #88\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0000e+00\n",
      "batch #89\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #90\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0000e+00\n",
      "batch #91\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0000e+00\n",
      "batch #92\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0000e+00\n",
      "batch #93\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0000e+00\n",
      "batch #94\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 301.4928\n",
      "batch #95\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0000e+00\n",
      "batch #96\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #97\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0000e+00\n",
      "batch #98\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0000e+00\n",
      "batch #99\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0000e+00\n",
      "batch #100\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0000e+00\n",
      "batch #101\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0000e+00\n",
      "batch #102\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0000e+00\n",
      "batch #103\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0000e+00\n",
      "batch #104\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0000e+00\n",
      "batch #105\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0000e+00\n",
      "batch #106\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0000e+00\n",
      "batch #107\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0000e+00\n",
      "batch #108\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 22.2632\n",
      "batch #109\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0000e+00\n",
      "batch #110\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0000e+00\n",
      "batch #111\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0000e+00\n",
      "batch #112\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0000e+00\n",
      "batch #113\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0000e+00\n",
      "batch #114\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 560.7357\n",
      "batch #115\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0000e+00\n",
      "batch #116\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0000e+00\n",
      "batch #117\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0000e+00\n",
      "batch #118\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0000e+00\n",
      "batch #119\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0000e+00\n",
      "batch #120\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0000e+00\n",
      "batch #121\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 24.4789\n",
      "batch #122\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0000e+00\n",
      "batch #123\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0000e+00\n",
      "batch #124\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0000e+00\n",
      "batch #125\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0000e+00\n",
      "batch #126\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0000e+00\n",
      "batch #127\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0000e+00\n",
      "batch #128\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0000e+00\n",
      "batch #129\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0000e+00\n",
      "batch #130\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0000e+00\n",
      "batch #131\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0000e+00\n",
      "batch #132\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0000e+00\n",
      "batch #133\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 178.7240\n",
      "batch #134\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0000e+00\n",
      "batch #135\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0000e+00\n",
      "batch #136\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "iterator = iter(dataset)\n",
    "batch_size = 64\n",
    "num_epochs = 2\n",
    "num_batches_per_epoch = int(1408/64)\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"---------------- on epoch number: {epoch+1}\")\n",
    "    iterator = iter(dataset)\n",
    "    for batch in range(num_batches_per_epoch):\n",
    "        print(f'batch #{batch}')\n",
    "        x_batch, y_batch = next(iterator)\n",
    "        model.fit(x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "64e44f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dir = './test'\n",
    "test_images= image_dataset_from_directory(test_dir, labels='inferred',image_size = (250,250),batch_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "f769dfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "tf.Tensor([0 1 1 0 1 1 0], shape=(7,), dtype=int32)\n",
      "7\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} slice index 7 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9862/488976842.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7214\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7215\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} slice index 7 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "(test_data,test_labels) = next(iter(test_images))\n",
    "pred = model.predict(test_data)\n",
    "print(pred)\n",
    "print(test_labels)\n",
    "print(len(test_data))\n",
    "print(len(test_data[7][0][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df203933",
   "metadata": {},
   "source": [
    "## Question:  Why are all the predictions perfect even though I put a desert picture in the forest directory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "19a2cd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 files belonging to 2 classes.\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "[[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "tf.Tensor([1 0 1 1 1 0 0], shape=(7,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "path = './test/'\n",
    "images = tf.keras.utils.image_dataset_from_directory(path,image_size=(250,250))\n",
    "(imgs,labels) = next(iter(images))\n",
    "preds = model.predict(imgs)\n",
    "print(preds)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "60003f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "250\n",
      "3\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "file_path = \"./test/forest/forest1.png\"\n",
    "\n",
    "#path = './test/'\n",
    "image = tf.io.read_file(file_path)\n",
    "image = tf.image.decode_jpeg(image, channels=3)\n",
    "image = tf.image.resize(image, [250, 250])\n",
    "#plt.imshow(image)\n",
    "#plt.show()\n",
    "print(len(image))\n",
    "print(len(image[0]))\n",
    "print(len(image[0][0]))\n",
    "\n",
    "#images = tf.constant(image,shape=(None,image.ndim),dtype='float32')\n",
    "\n",
    "pred = model.predict(np.array([image]))\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f73a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
